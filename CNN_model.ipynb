{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout, Input, Concatenate, GlobalAvgPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import json\n",
    "from evaluator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "VARIABLES = ['ActivityCounts', 'Barometer', 'BloodPerfusion',\n",
    "             'BloodPulseWave', 'EnergyExpenditure', 'GalvanicSkinResponse', 'HR',\n",
    "             'HRV', 'RESP', 'Steps', 'SkinTemperature', 'ActivityClass']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "GRAYSCALE = False # grayscale or rgb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# file path to data folder\n",
    "path = './Output'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# dimensions\n",
    "N, HEIGHT, WIDTH, CHANNELS = sum([1 for p in os.listdir(path) if (p[:14] == 'feature_vector' and p[:19] != 'feature_vector_stat')]), \\\n",
    "                             *np.load(path + '/feature_vector0.npy').shape\n",
    "CHANNELS = len(VARIABLES) if GRAYSCALE else CHANNELS # reduce channels for grayscale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metadata (subjectID etc.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open(path + '/metadata.txt') as f:\n",
    "    metadata = f.read()\n",
    "\n",
    "metadata = json.loads(metadata.replace('\\'', '\\\"').replace('False', 'false').replace('True', 'true')) # doesn't accept other chars"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "subjects = [meta['subjectID'] for meta in metadata]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Addditional functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# image-wise transformer\n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"greyscale = 0.2989 * red + 0.5870 * green + 0.1140 * blue\"\"\"\n",
    "    return np.dot(rgb[:, :, :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# loss function\n",
    "def weighted_cross_entropy(weight):\n",
    "    def weighted_cross_entropy_with_logits(labels, logits):\n",
    "        loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "            labels, logits, weight\n",
    "        )\n",
    "        return loss\n",
    "    return weighted_cross_entropy_with_logits\n",
    "\n",
    "# weight (imbalanced classes)\n",
    "def check_imbalance(path_to_labels, indices):\n",
    "    \"\"\"Returns indices of positives/negatives\"\"\"\n",
    "    y = np.empty((len(indices), 2), dtype=int)\n",
    "    for i, index in enumerate(indices):\n",
    "        y[i, ] = np.load(path_to_labels + f'/labels{index}.npy', allow_pickle=True)\n",
    "\n",
    "    positives = np.where(y[:, variable] == 1)[0] # TODO: for now just one variable\n",
    "    negatives = np.where(y[:, variable] == 0)[0] # TODO: for now just one variable\n",
    "\n",
    "    return np.array(indices)[positives], np.array(indices)[negatives]\n",
    "\n",
    "def get_weighting_factor(path, train_set_indices):\n",
    "    positives, negatives = check_imbalance(path, train_set_indices)\n",
    "    sample_weight = len(negatives) / len(positives) # for weighted cross-entropy\n",
    "    return sample_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataloader (dataset with images too large)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, data_path: str, indices_dataset: list, batch_size=32, dim=(HEIGHT, WIDTH), n_channels=CHANNELS, shuffle=True):\n",
    "        self.data_path = data_path # path to full dataset\n",
    "        self.dim = dim # image dimension\n",
    "        self.batch_size = batch_size\n",
    "        self.indices_dataset = indices_dataset # indices of full dataset (different for train/validation/test set)\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.on_epoch_end() # shuffle data for each epoch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Shuffle data for each epoch\n",
    "        \"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices_dataset)\n",
    "\n",
    "    def __data_generation(self, indices):\n",
    "        \"\"\"\n",
    "        Loads and returns datapoints[indices]\n",
    "        \"\"\"\n",
    "        # init\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty(self.batch_size, dtype=float) # TODO: int for non-logits\n",
    "\n",
    "        # load individual datapoints\n",
    "        for i, index in enumerate(indices):\n",
    "            images = np.load(self.data_path + f'/feature_vector{index}.npy', allow_pickle=True)\n",
    "            if GRAYSCALE:\n",
    "                images_gray = np.empty((HEIGHT, WIDTH, self.n_channels))\n",
    "                for j in range(len(VARIABLES)):\n",
    "                    image_rgb = images[:, :, (3 * j): (3 * (j + 1))]\n",
    "                    image_gray = rgb2gray(image_rgb)\n",
    "                    images_gray[:, :, j] = image_gray\n",
    "                images = images_gray\n",
    "\n",
    "            X[i, ] = images\n",
    "            y[i] = np.load(self.data_path + f'/labels{index}.npy', allow_pickle=True)[variable] # TODO: for now just one variable\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.indices_dataset) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generates batch[index]\n",
    "        \"\"\"\n",
    "        # calculate indices of batch\n",
    "        indices = self.indices_dataset[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # generate batch\n",
    "        X, y = self.__data_generation(indices)\n",
    "\n",
    "        return X, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# TODO: make possible for grayscale\n",
    "class ConvNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, name='cnn', **kwargs):\n",
    "        super(ConvNet, self).__init__(name, **kwargs)\n",
    "\n",
    "        self.in_shape = (HEIGHT, WIDTH, CHANNELS)\n",
    "        self.in_shape_mobilenet = (HEIGHT, WIDTH, 3)\n",
    "\n",
    "        # MobileNetV2 embedding\n",
    "        self.mobilenet = MobileNetV2(input_shape=self.in_shape_mobilenet, weights='imagenet', include_top=False)\n",
    "        self.mobilenet._name = 'mobilenet'\n",
    "        self.mobilenet.trainable = False\n",
    "        self.finetuning = False\n",
    "        self.out_shape_mobilenet = self.mobilenet.layers[-1].output_shape # for one spectrogram\n",
    "\n",
    "        # Concatenation\n",
    "        self.concat = Concatenate(name='concat')\n",
    "\n",
    "        # Global pooling\n",
    "        self.pool = GlobalAvgPool2D(name='global_avg_pool')\n",
    "\n",
    "        # TODO: more sophisticated dense (dropout, regularizer, init., ...)\n",
    "        # Fully-connected network\n",
    "        self.flatten = Flatten(name='flatten', input_shape=(self.out_shape_mobilenet * (CHANNELS // 3), ))\n",
    "        self.dense = Dense(1, name='dense') # keep logits\n",
    "        self.out_shape = 1\n",
    "\n",
    "        # build graph\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None, *self.in_shape))\n",
    "        x = Input(shape=self.in_shape)\n",
    "        Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "    def set_finetuning(self, mode=True):\n",
    "        self.finetuning = mode\n",
    "        self.mobilenet.trainable = mode\n",
    "\n",
    "        for layers in self.mobilenet.layers:\n",
    "            layers.trainable = False\n",
    "\n",
    "        # \"activate\" last conv layer of MobileNet\n",
    "        self.mobilenet.layers[-3].trainable = mode\n",
    "        self.mobilenet.layers[-2].trainable = mode\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Model predictions (logits)\n",
    "        :param inputs: all spectrograms of shape (HEIGHT, WIDTH, CHANNELS)\n",
    "        :return: class prediction (logits)\n",
    "        \"\"\"\n",
    "        # MobileNetV2 embeddings\n",
    "        x = [self.mobilenet(inputs[..., i:i+3], training=self.finetuning) for i in range(0, CHANNELS, 3)]\n",
    "\n",
    "        # Concatenation\n",
    "        x = self.concat(x)\n",
    "\n",
    "        # Global pooling\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Fully-connected network\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class CNN:\n",
    "\n",
    "    def __init__(self, path, variable, epochs, learning_rate, batch_size):\n",
    "        self.model = ConvNet()\n",
    "        self.path = path\n",
    "        assert variable in (0, 1)\n",
    "        self.variable = variable\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.history = None\n",
    "\n",
    "    def fit(self, train_indices):\n",
    "        # training set\n",
    "        train_dataloader = DataGenerator(self.path, train_indices, batch_size=self.batch_size)\n",
    "\n",
    "        # weights for loss function\n",
    "        sample_weights = get_weighting_factor(self.path, train_indices)\n",
    "\n",
    "        # build model\n",
    "        self.model.compile(optimizer=Adam(learning_rate=self.learning_rate),\n",
    "                           loss=weighted_cross_entropy(sample_weights))\n",
    "\n",
    "        # training\n",
    "        self.history = self.model.fit_generator(generator=train_dataloader,\n",
    "                                                epochs=self.epochs)\n",
    "\n",
    "    def predict(self, test_indices):\n",
    "        \"\"\"Predicts actual class labels (not logits/probability values!)\"\"\"\n",
    "        # TODO: make more efficient\n",
    "        # test set + predict\n",
    "        y_pred = np.empty(len(test_indices), dtype=float)\n",
    "\n",
    "        for i, index in enumerate(test_indices):\n",
    "            X_i = np.load(path + f'/feature_vector{index}.npy', allow_pickle=True)\n",
    "\n",
    "            X_i = tf.expand_dims(X_i, axis=0) # add \"batch dimension\"\n",
    "            logits_pred_i = self.model.predict(X_i)\n",
    "\n",
    "            y_pred[i] = logits_pred_i\n",
    "\n",
    "        y_probs = tf.math.sigmoid(y_pred) # logits to probs\n",
    "        y_pred = tf.round(y_probs) # probs to labels\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Starting stratified group 5-fold for physical fatigue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 54s 320ms/step - loss: 0.4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 1 F1: 0.12546230440967282:  20%|██        | 1/5 [01:10<04:41, 70.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 37s 318ms/step - loss: 0.4519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 2 F1: 0.6803314371701809:  40%|████      | 2/5 [03:15<05:07, 102.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 45s 323ms/step - loss: 0.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 3 F1: 0.1843882723567555:  60%|██████    | 3/5 [04:41<03:09, 94.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 48s 328ms/step - loss: 0.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 4 F1: 0.8519713261648746:  80%|████████  | 4/5 [05:43<01:22, 82.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 45s 327ms/step - loss: 0.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 5 F1: 0.6352068401860933: 100%|██████████| 5/5 [07:05<00:00, 85.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance model:\n",
      " accuracy: 0.534 +- 0.232 \n",
      "\n",
      " balanced_accuracy: 0.626 +- 0.103 \n",
      "\n",
      " f1: 0.495 +- 0.288 \n",
      "\n",
      " recall: 0.534 +- 0.232 \n",
      "\n",
      " precision: 0.647 +- 0.289 \n",
      "\n",
      "Starting stratified 5-fold for physical fatigue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 46s 326ms/step - loss: 0.3146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 1 F1: 0.6363659596217736:  20%|██        | 1/5 [01:23<05:34, 83.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 46s 319ms/step - loss: 0.2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 2 F1: 0.6201637086250744:  40%|████      | 2/5 [02:47<04:10, 83.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 44s 318ms/step - loss: 0.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 3 F1: 0.7250272290143972:  60%|██████    | 3/5 [04:15<02:51, 85.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 41s 314ms/step - loss: 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 4 F1: 0.645823112604059:  80%|████████  | 4/5 [05:35<01:23, 83.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 43s 320ms/step - loss: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 5 F1: 0.8504483983760772: 100%|██████████| 5/5 [07:03<00:00, 84.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance model:\n",
      " accuracy: 0.68 +- 0.091 \n",
      "\n",
      " balanced_accuracy: 0.765 +- 0.031 \n",
      "\n",
      " f1: 0.696 +- 0.085 \n",
      "\n",
      " recall: 0.68 +- 0.091 \n",
      "\n",
      " precision: 0.847 +- 0.007 \n",
      "\n",
      "Starting leave-one-subject-out for physical fatigue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 46s 316ms/step - loss: 0.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 1 F1: 0.7833333333333333:   4%|▍         | 1/24 [00:56<21:32, 56.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 47s 320ms/step - loss: 0.2345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 2 F1: 0.49951219512195116:   8%|▊         | 2/24 [01:53<20:48, 56.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 59s 341ms/step - loss: 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 3 F1: 0.7215865751334858:  12%|█▎        | 3/24 [03:02<21:49, 62.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 47s 322ms/step - loss: 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 4 F1: 1.0:  17%|█▋        | 4/24 [03:59<20:04, 60.22s/it]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 48s 324ms/step - loss: 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 5 F1: 0.5666666666666667:  21%|██        | 5/24 [04:55<18:37, 58.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 57s 317ms/step - loss: 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 6 F1: 0.9404081632653061:  25%|██▌       | 6/24 [06:02<18:28, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 47s 331ms/step - loss: 0.1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 7 F1: 0.8368831168831167:  29%|██▉       | 7/24 [07:01<17:13, 60.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 50s 342ms/step - loss: 0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 8 F1: 0.9542857142857143:  33%|███▎      | 8/24 [08:02<16:12, 60.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 52s 370ms/step - loss: 0.1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 9 F1: 0.8423180592991916:  38%|███▊      | 9/24 [09:05<15:24, 61.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 64s 377ms/step - loss: 0.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 10 F1: 0.8860164512338425:  42%|████▏     | 10/24 [10:21<15:20, 65.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 53s 405ms/step - loss: 0.1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 11 F1: 0.9120370370370369:  46%|████▌     | 11/24 [11:25<14:10, 65.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 57s 421ms/step - loss: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 12 F1: 0.9523809523809524:  50%|█████     | 12/24 [12:33<13:15, 66.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 58s 423ms/step - loss: 0.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Fold 12 F1: 0.9523809523809524:  50%|█████     | 12/24 [13:36<13:36, 68.03s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    for variable in (0, 1): # phF, MF\n",
    "        model = CNN(path, variable=0, epochs=1, learning_rate=1e-3, batch_size=16)\n",
    "\n",
    "        scores_strat_group_k_fold = stratified_group_k_fold(path=path,\n",
    "                                                            groups=subjects,\n",
    "                                                            model=model,\n",
    "                                                            folds=5,\n",
    "                                                            images=True,\n",
    "                                                            verbose=True,\n",
    "                                                            variable=variable)\n",
    "\n",
    "        scores_strat_k_fold = stratified_k_fold(path=path,\n",
    "                                                groups=subjects,\n",
    "                                                model=model,\n",
    "                                                folds=5,\n",
    "                                                images=True,\n",
    "                                                verbose=True,\n",
    "                                                variable=variable)\n",
    "\n",
    "        scores_loso = leave_one_subject_out(path=path,\n",
    "                                            groups=subjects,\n",
    "                                            model=model,\n",
    "                                            images=True,\n",
    "                                            verbose=True,\n",
    "                                            variable=variable)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}